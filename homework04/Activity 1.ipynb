{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) I parced the arguments by using the split function on the subreddits argument passed to the function. I appended each argument to a list of subreddits. Once I had these individual subreddits, I fetched data on each to create a dictionary. In thes dictionaries, I utlizied the \"data\" and appended that to a final dictionary of data.\n",
    "2) I made a function that fetched the data by using the .get() function to extract the data from the network and using the json function on this information to create a neat dictionary of this information. For each of these dictionaries, I looped through and appended certain data to a seperate dictionary for later use.\n",
    "3) I created a table very similar to the class example. I sorted the data in reverse order and for the data, I HTML to create different columns, links, and bolded fonts. The columns for the HTML table were urls, titles, scores, and permalinks. In a for loop, this HTML code was added to a long string and eventually displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_subreddit(subreddit):\n",
    "    for x in range(0,20): \n",
    "        headers  = {'user-agent': 'reddit-{}'.format(os.environ['USER'])}\n",
    "        url = 'https://www.reddit.com/r/' + subreddit + '/.json'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "    children = response.json()['data']['children']\n",
    "    return children\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multireddit(subreddits, limit=5, orderby='score'):\n",
    "    ''' Displays an HTML listing of the top `limit` articles from the\n",
    "    various `subreddits` specified by the user.  These articles will be\n",
    "    sorted by the field specified by `orderby`\n",
    "\n",
    "      - `subreddits` is a comma-separated list of subreddits (ie.\n",
    "        `linux,linuxmasterrace`)\n",
    "\n",
    "      - `orderby` is any field in the Reddit JSON data for a particular\n",
    "        article (ie. `score`, `title`, `created_utc`, etc.)\n",
    "    '''\n",
    "    \n",
    "    # If subreddits is empty, do nothing\n",
    "    if not subreddits:\n",
    "        return\n",
    "    \n",
    "    subs = list()\n",
    "    data = list()\n",
    "    \n",
    "    for subreddit in subreddits.split(','):\n",
    "        subs.append(subreddit)\n",
    "    \n",
    "    for subreddit in subs:\n",
    "        children = fetch_subreddit(subreddit)\n",
    "        for child in children:\n",
    "            data.append(child['data'])\n",
    "        \n",
    "    html = '<table><tbody>'\n",
    "    \n",
    "    for index, article in enumerate(sorted(data, key=lambda a: a[orderby],reverse=True)[:limit]):\n",
    "        html += '''\n",
    "        <tr>\n",
    "            <td>{}</td>\n",
    "            <td style=\"text-align: left\"><a href=\"{}\">{}</a></td>\n",
    "            <td><b>Score: </b>{}</td>\n",
    "            <td><a href=\"{}\">Comments</a></td>\n",
    "        </tr>\n",
    "        '''.format(index + 1, article['url'], article['title'], article['score'], article['permalink'])\n",
    "        \n",
    "    html += '</tbody></table>'\n",
    "    \n",
    "    \n",
    "    # Display final HTML string\n",
    "    display(HTML(html))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f36f0eb574527a287276c5ae34634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.multireddit>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORDERBY = {\n",
    "    'Score': 'score',\n",
    "    'Creation Time': 'created_utc',\n",
    "    'Title': 'title'\n",
    "}\n",
    "\n",
    "interact(multireddit, subreddits='', limit=(1, 20), orderby=ORDERBY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
